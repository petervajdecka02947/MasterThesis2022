{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8c290bb-ed6e-4f7e-868e-e7c6acbf7daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers[torch]==4.10.0\n",
    "#!pip install --upgrade tensorflow\n",
    "#pip install --upgrade simplet5\n",
    "# !pip install pytorch-lightning==1.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3fd1a0-8893-4ee0-9a91-8cdce7b6af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68cf748-d316-46ce-a9e5-5085a833368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import notebook as tqdm\n",
    "#from simplet5 import SimpleT5\n",
    "import pandas as pd\n",
    "import re \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    Adafactor,\n",
    "    T5ForConditionalGeneration,\n",
    "    MT5ForConditionalGeneration,\n",
    "    #ByT5Tokenizer,\n",
    "    PreTrainedTokenizer,\n",
    "    T5TokenizerFast as T5Tokenizer,\n",
    "    MT5TokenizerFast as MT5Tokenizer,\n",
    ")\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# from fastT5 import export_and_get_onnx_model\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89793d07-507f-49f1-8862-87dc88846489",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_name = \"claim_LOF_base_0.45_0.575_11.905_data_explanation_prep_4.pickle\"                            #\"LOF_base_0.45_0.53_removed_inlier_outlier_23.782_full.pickle\"     # \"LOF_base_0.46_0.54_removed_inlier_outlier_0.51_full.pickle\"\n",
    "data_inpit_dir = \"./Data/Selection/\"                              #\"./Data/Selection/\" \"./Data/Preprocessed/\"   \n",
    "output_dir = \"./Data/Models/\"\n",
    "source_column = \"source_text_shorter\"    #source_text_shorter           \" statement_explanation_prep\"  #\"explanation_prep\"  \"statement_explanation_prep\"                     #\"source_text_shorter\"  # \"source_text_shorter\" source_text\n",
    "target_column =  \"target_text\"              #\"shortExplanation_prep\"                         #\"target_text\"\n",
    "\n",
    "no_workers = 1\n",
    "\n",
    "imput_data_path = data_inpit_dir + input_data_name\n",
    "#input_data_name = re.sub(r'.pickle', '', input_data_name)\n",
    "new_model_name = \"d-t5-{}_{}\".format(source_column, input_data_name) # datetime.now().strftime('%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95519ace-288a-45f6-a407-d92a27390b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A100-SXM4-40GB'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b8dcd5-f5ce-46d9-8678-8cbb976b089d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d-t5-source_text_shorter_claim_LOF_base_0.45_0.575_11.905_data_explanation_prep_4.pickle'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "511de6ea-b097-45d3-b812-7067b000980e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "pl.seed_everything(42)\n",
    "\n",
    "\n",
    "class PyTorchDataModule(Dataset):\n",
    "    \"\"\"  PyTorch Dataset class  \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        source_max_token_len: int = 512,\n",
    "        target_max_token_len: int = 512,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        initiates a PyTorch Dataset Module for input data\n",
    "        Args:\n",
    "            data (pd.DataFrame): input pandas dataframe. Dataframe must have 2 column --> \"source_text\" and \"target_text\"\n",
    "            tokenizer (PreTrainedTokenizer): a PreTrainedTokenizer (T5Tokenizer, MT5Tokenizer, or ByT5Tokenizer)\n",
    "            source_max_token_len (int, optional): max token length of source text. Defaults to 512.\n",
    "            target_max_token_len (int, optional): max token length of target text. Defaults to 512.\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.source_max_token_len = source_max_token_len\n",
    "        self.target_max_token_len = target_max_token_len\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" returns length of data \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\" returns dictionary of input tensors to feed into T5/MT5 model\"\"\"\n",
    "\n",
    "        data_row = self.data.iloc[index]\n",
    "        source_text = data_row[\"source_text\"]\n",
    "\n",
    "        source_text_encoding = self.tokenizer(\n",
    "            source_text,\n",
    "            max_length=self.source_max_token_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        target_text_encoding = self.tokenizer(\n",
    "            data_row[\"target_text\"],\n",
    "            max_length=self.target_max_token_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        labels = target_text_encoding[\"input_ids\"]\n",
    "        labels[\n",
    "            labels == 0\n",
    "        ] = -100  # to make sure we have correct labels for T5 text generation\n",
    "\n",
    "        return dict(\n",
    "            source_text=source_text,\n",
    "            target_text=data_row[\"target_text\"],\n",
    "            source_text_input_ids=source_text_encoding[\"input_ids\"].flatten(),\n",
    "            source_text_attention_mask=source_text_encoding[\"attention_mask\"].flatten(),\n",
    "            labels=labels.flatten(),\n",
    "            labels_attention_mask=target_text_encoding[\"attention_mask\"].flatten(),\n",
    "        )\n",
    "\n",
    "\n",
    "class LightningDataModule(pl.LightningDataModule):\n",
    "    \"\"\" PyTorch Lightning data class \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df: pd.DataFrame,\n",
    "        test_df: pd.DataFrame,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        batch_size: int = 4,\n",
    "        source_max_token_len: int = 512,\n",
    "        target_max_token_len: int = 512,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        initiates a PyTorch Lightning Data Module\n",
    "        Args:\n",
    "            train_df (pd.DataFrame): training dataframe. Dataframe must contain 2 columns --> \"source_text\" & \"target_text\"\n",
    "            test_df (pd.DataFrame): validation dataframe. Dataframe must contain 2 columns --> \"source_text\" & \"target_text\"\n",
    "            tokenizer (PreTrainedTokenizer): PreTrainedTokenizer (T5Tokenizer, MT5Tokenizer, or ByT5Tokenizer)\n",
    "            batch_size (int, optional): batch size. Defaults to 4.\n",
    "            source_max_token_len (int, optional): max token length of source text. Defaults to 512.\n",
    "            target_max_token_len (int, optional): max token length of target text. Defaults to 512.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.source_max_token_len = source_max_token_len\n",
    "        self.target_max_token_len = target_max_token_len\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = PyTorchDataModule(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.source_max_token_len,\n",
    "            self.target_max_token_len,\n",
    "        )\n",
    "        self.test_dataset = PyTorchDataModule(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.source_max_token_len,\n",
    "            self.target_max_token_len,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\" training dataloader \"\"\"\n",
    "        return DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers = no_workers\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        \"\"\" test dataloader \"\"\"\n",
    "        return DataLoader(\n",
    "            self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers = no_workers\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \"\"\" validation dataloader \"\"\"\n",
    "        return DataLoader(\n",
    "            self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers = no_workers\n",
    "        )\n",
    "\n",
    "\n",
    "class LightningModel(pl.LightningModule):\n",
    "    \"\"\" PyTorch Lightning Model class\"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer, model, outputdir: str = \"outputs\"):\n",
    "        \"\"\"\n",
    "        initiates a PyTorch Lightning Model\n",
    "        Args:\n",
    "            tokenizer : T5/MT5/ByT5 tokenizer\n",
    "            model : T5/MT5/ByT5 model\n",
    "            outputdir (str, optional): output directory to save model checkpoints. Defaults to \"outputs\".\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.outputdir = outputdir\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, decoder_attention_mask, labels=None):\n",
    "        \"\"\" forward step \"\"\"\n",
    "        output = self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "        )\n",
    "\n",
    "        return output.loss, output.logits\n",
    "\n",
    "    def training_step(self, batch, batch_size):\n",
    "        \"\"\" training step \"\"\"\n",
    "        input_ids = batch[\"source_text_input_ids\"]\n",
    "        attention_mask = batch[\"source_text_attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
    "\n",
    "        loss, outputs = self(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_attention_mask=labels_attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_size):\n",
    "        \"\"\" validation step \"\"\"\n",
    "        input_ids = batch[\"source_text_input_ids\"]\n",
    "        attention_mask = batch[\"source_text_attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
    "\n",
    "        loss, outputs = self(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_attention_mask=labels_attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_size):\n",
    "        \"\"\" test step \"\"\"\n",
    "        input_ids = batch[\"source_text_input_ids\"]\n",
    "        attention_mask = batch[\"source_text_attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
    "\n",
    "        loss, outputs = self(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_attention_mask=labels_attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\" configure optimizers \"\"\"\n",
    "        return Adafactor(self.parameters(), lr=0.001, scale_parameter=False, relative_step=False)\n",
    "\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        \"\"\" save tokenizer and model on epoch end \"\"\"\n",
    "        avg_traning_loss = np.round(\n",
    "            torch.mean(torch.stack([x[\"loss\"] for x in training_step_outputs])).item(),\n",
    "            4,\n",
    "        )\n",
    "        self.avg_traning_loss = avg_traning_loss\n",
    "        path = f\"{self.outputdir}/simplet5-epoch-{self.current_epoch}-train-loss-{str(avg_traning_loss)}\"\n",
    "        print(\"Average training loss for epoch {} equal to {}\".format(self.current_epoch,self.avg_traning_loss))\n",
    "        #self.tokenizer.save_pretrained(path)\n",
    "        #self.model.save_pretrained(path)\n",
    "\n",
    "    # def validation_epoch_end(self, validation_step_outputs):\n",
    "    #     # val_loss = torch.stack([x['loss'] for x in validation_step_outputs]).mean()\n",
    "    #     path = f\"{self.outputdir}/T5-epoch-{self.current_epoch}\"\n",
    "    #     self.tokenizer.save_pretrained(path)\n",
    "    #     # self.model.save_pretrained(path)\n",
    "\n",
    "\n",
    "class SimpleT5:\n",
    "    \"\"\" Custom SimpleT5 class \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\" initiates SimpleT5 class \"\"\"\n",
    "        pass\n",
    "\n",
    "    def from_pretrained(self, model_type=\"t5\", model_name=\"t5-base\") -> None:\n",
    "        \"\"\"\n",
    "        loads T5/MT5 Model model for training/finetuning\n",
    "        Args:\n",
    "            model_type (str, optional): \"t5\" or \"mt5\" . Defaults to \"t5\".\n",
    "            model_name (str, optional): exact model architecture name, \"t5-base\" or \"t5-large\". Defaults to \"t5-base\".\n",
    "        \"\"\"\n",
    "        if model_type == \"t5\":\n",
    "            self.tokenizer = T5Tokenizer.from_pretrained(f\"{model_name}\")\n",
    "            self.model = T5ForConditionalGeneration.from_pretrained(\n",
    "                f\"{model_name}\", return_dict=True\n",
    "            )\n",
    "        elif model_type == \"mt5\":\n",
    "            self.tokenizer = MT5Tokenizer.from_pretrained(f\"{model_name}\")\n",
    "            self.model = MT5ForConditionalGeneration.from_pretrained(\n",
    "                f\"{model_name}\", return_dict=True\n",
    "            )\n",
    "        elif model_type == \"byt5\":\n",
    "            self.tokenizer = ByT5Tokenizer.from_pretrained(f\"{model_name}\")\n",
    "            self.model = T5ForConditionalGeneration.from_pretrained(\n",
    "                f\"{model_name}\", return_dict=True\n",
    "            )\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        train_df: pd.DataFrame,\n",
    "        eval_df: pd.DataFrame,\n",
    "        source_max_token_len: int = 512,\n",
    "        target_max_token_len: int = 512,\n",
    "        batch_size: int = 8,\n",
    "        max_epochs: int = 5,\n",
    "        use_gpu: bool = True,\n",
    "        outputdir: str = \"outputs\",\n",
    "        early_stopping_patience_epochs: int = 0,  # 0 to disable early stopping feature\n",
    "        precision=32,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        trains T5/MT5 model on custom dataset\n",
    "        Args:\n",
    "            train_df (pd.DataFrame): training datarame. Dataframe must have 2 column --> \"source_text\" and \"target_text\"\n",
    "            eval_df ([type], optional): validation datarame. Dataframe must have 2 column --> \"source_text\" and \"target_text\"\n",
    "            source_max_token_len (int, optional): max token length of source text. Defaults to 512.\n",
    "            target_max_token_len (int, optional): max token length of target text. Defaults to 512.\n",
    "            batch_size (int, optional): batch size. Defaults to 8.\n",
    "            max_epochs (int, optional): max number of epochs. Defaults to 5.\n",
    "            use_gpu (bool, optional): if True, model uses gpu for training. Defaults to True.\n",
    "            outputdir (str, optional): output directory to save model checkpoints. Defaults to \"outputs\".\n",
    "            early_stopping_patience_epochs (int, optional): monitors val_loss on epoch end and stops training, if val_loss does not improve after the specied number of epochs. set 0 to disable early stopping. Defaults to 0 (disabled)\n",
    "            precision (int, optional): sets precision training - Double precision (64), full precision (32) or half precision (16). Defaults to 32.\n",
    "        \"\"\"\n",
    "        self.target_max_token_len = target_max_token_len\n",
    "        self.data_module = LightningDataModule(\n",
    "            train_df,\n",
    "            eval_df,\n",
    "            self.tokenizer,\n",
    "            batch_size=batch_size,\n",
    "            source_max_token_len=source_max_token_len,\n",
    "            target_max_token_len=target_max_token_len,\n",
    "        )\n",
    "\n",
    "        self.T5Model = LightningModel(\n",
    "            tokenizer = self.tokenizer, model=self.model, outputdir=outputdir\n",
    "        )\n",
    "\n",
    "        # checkpoint_callback = ModelCheckpoint(\n",
    "        #     dirpath=\"checkpoints\",\n",
    "        #     filename=\"best-checkpoint-{epoch}-{train_loss:.2f}\",\n",
    "        #     save_top_k=-1,\n",
    "        #     verbose=True,\n",
    "        #     monitor=\"train_loss\",\n",
    "        #     mode=\"min\",\n",
    "        # )\n",
    "\n",
    "        # logger = TensorBoardLogger(\"SimpleT5\", name=\"SimpleT5-Logger\")\n",
    "\n",
    "        early_stop_callback = (\n",
    "            [\n",
    "                EarlyStopping(\n",
    "                    monitor=\"val_loss\",\n",
    "                    min_delta=0.00,\n",
    "                    patience=early_stopping_patience_epochs,\n",
    "                    verbose=True,\n",
    "                    mode=\"min\",\n",
    "                )\n",
    "            ]\n",
    "            if early_stopping_patience_epochs > 0\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        gpus = 1 if use_gpu else 0\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            # logger=logger,\n",
    "            callbacks=early_stop_callback,\n",
    "            max_epochs=max_epochs,\n",
    "            gpus=gpus,\n",
    "            progress_bar_refresh_rate = 5,\n",
    "            precision=precision\n",
    "        )\n",
    "\n",
    "        trainer.fit(self.T5Model, self.data_module)\n",
    "        #path = f\"{self.T5Model.outputdir}/simplet5-epoch-{self.T5Model.current_epoch}-train-loss-{str(self.T5Model.avg_traning_loss)}\"\n",
    "        path = f\"{self.T5Model.outputdir}\" + new_model_name\n",
    "        #print(str(avg_traning_loss))\n",
    "        self.tokenizer.save_pretrained(path)\n",
    "        self.model.save_pretrained(path)\n",
    "\n",
    "    def load_model(\n",
    "        self, model_type: str = \"t5\", model_dir: str = \"outputs\", use_gpu: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        loads a checkpoint for inferencing/prediction\n",
    "        Args:\n",
    "            model_type (str, optional): \"t5\" or \"mt5\". Defaults to \"t5\".\n",
    "            model_dir (str, optional): path to model directory. Defaults to \"outputs\".\n",
    "            use_gpu (bool, optional): if True, model uses gpu for inferencing/prediction. Defaults to True.\n",
    "        \"\"\"\n",
    "        if model_type == \"t5\":\n",
    "            self.model = T5ForConditionalGeneration.from_pretrained(f\"{model_dir}\")\n",
    "            self.tokenizer = T5Tokenizer.from_pretrained(f\"{model_dir}\")\n",
    "        elif model_type == \"mt5\":\n",
    "            self.model = MT5ForConditionalGeneration.from_pretrained(f\"{model_dir}\")\n",
    "            self.tokenizer = MT5Tokenizer.from_pretrained(f\"{model_dir}\")\n",
    "        elif model_type == \"byt5\":\n",
    "            self.model = T5ForConditionalGeneration.from_pretrained(f\"{model_dir}\")\n",
    "            self.tokenizer = ByT5Tokenizer.from_pretrained(f\"{model_dir}\")\n",
    "\n",
    "        if use_gpu:\n",
    "            if torch.cuda.is_available():\n",
    "                self.device = torch.device(\"cuda\")\n",
    "            else:\n",
    "                raise \"exception ---> no gpu found. set use_gpu=False, to use CPU\"\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        source_text: str,\n",
    "        max_length: int = 512,\n",
    "        num_return_sequences: int = 1,\n",
    "        num_beams: int = 2,\n",
    "        top_k: int = 50,\n",
    "        top_p: float = 0.95,\n",
    "        do_sample: bool = True,\n",
    "        repetition_penalty: float = 2.5,\n",
    "        length_penalty: float = 1.0,\n",
    "        early_stopping: bool = True,\n",
    "        skip_special_tokens: bool = True,\n",
    "        clean_up_tokenization_spaces: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        generates prediction for T5/MT5 model\n",
    "        Args:\n",
    "            source_text (str): any text for generating predictions\n",
    "            max_length (int, optional): max token length of prediction. Defaults to 512.\n",
    "            num_return_sequences (int, optional): number of predictions to be returned. Defaults to 1.\n",
    "            num_beams (int, optional): number of beams. Defaults to 2.\n",
    "            top_k (int, optional): Defaults to 50.\n",
    "            top_p (float, optional): Defaults to 0.95.\n",
    "            do_sample (bool, optional): Defaults to True.\n",
    "            repetition_penalty (float, optional): Defaults to 2.5.\n",
    "            length_penalty (float, optional): Defaults to 1.0.\n",
    "            early_stopping (bool, optional): Defaults to True.\n",
    "            skip_special_tokens (bool, optional): Defaults to True.\n",
    "            clean_up_tokenization_spaces (bool, optional): Defaults to True.\n",
    "        Returns:\n",
    "            list[str]: returns predictions\n",
    "        \"\"\"\n",
    "        input_ids = self.tokenizer.encode(\n",
    "            source_text, return_tensors=\"pt\", add_special_tokens=True\n",
    "        )\n",
    "        input_ids = input_ids.to(self.device)\n",
    "        generated_ids = self.model.generate(\n",
    "            input_ids=input_ids,\n",
    "            num_beams=num_beams,\n",
    "            max_length=max_length,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            length_penalty=length_penalty,\n",
    "            early_stopping=early_stopping,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "        )\n",
    "        preds = [\n",
    "            self.tokenizer.decode(\n",
    "                g,\n",
    "                skip_special_tokens=skip_special_tokens,\n",
    "                clean_up_tokenization_spaces=clean_up_tokenization_spaces,\n",
    "            )\n",
    "            for g in generated_ids\n",
    "        ]\n",
    "        return preds\n",
    "\n",
    "    # def convert_and_load_onnx_model(self, model_dir: str):\n",
    "    #     \"\"\" returns ONNX model \"\"\"\n",
    "    #     self.onnx_model = export_and_get_onnx_model(model_dir)\n",
    "    #     self.onnx_tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "    # def onnx_predict(self, source_text: str):\n",
    "    #     \"\"\" generates prediction from ONNX model \"\"\"\n",
    "    #     token = self.onnx_tokenizer(source_text, return_tensors=\"pt\")\n",
    "    #     tokens = self.onnx_model.generate(\n",
    "    #         input_ids=token[\"input_ids\"],\n",
    "    #         attention_mask=token[\"attention_mask\"],\n",
    "    #         num_beams=2,\n",
    "    #     )\n",
    "    #     output = self.onnx_tokenizer.decode(tokens.squeeze(), skip_special_tokens=True)\n",
    "    #     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3f32c37-17db-4463-87d2-926673bcdb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(imput_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f721fa62-9d0d-4947-9e38-7b98e441e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev_test = train_test_split(data, test_size = 0.2, random_state = 42)\n",
    "dev, test = train_test_split(dev_test, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ffbe5d9-7a5f-4f21-9ac2-5caeced69a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_len</th>\n",
       "      <th>source_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10312.000000</td>\n",
       "      <td>10312.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>85.508146</td>\n",
       "      <td>731.882758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>41.681467</td>\n",
       "      <td>270.750197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>540.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>696.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>106.250000</td>\n",
       "      <td>879.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>775.000000</td>\n",
       "      <td>2925.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target_len    source_len\n",
       "count  10312.000000  10312.000000\n",
       "mean      85.508146    731.882758\n",
       "std       41.681467    270.750197\n",
       "min        2.000000     41.000000\n",
       "25%       58.000000    540.000000\n",
       "50%       80.000000    696.000000\n",
       "75%      106.250000    879.000000\n",
       "max      775.000000   2925.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target_text'] = train[target_column]\n",
    "train['source_text'] = \"summarize: \" + train[source_column]\n",
    "\n",
    "train['target_len'] = train[\"target_text\"].str.split().str.len()\n",
    "train['source_len'] = train[\"source_text\"].str.split().str.len()\n",
    "train[['target_len','source_len']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d755764-5d19-4801-8ce7-1a4c6383eaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10312"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2060fdd-5bba-401a-a9ec-bc2b267148df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_len</th>\n",
       "      <th>source_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1289.000000</td>\n",
       "      <td>1289.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>85.415050</td>\n",
       "      <td>737.681924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>41.921667</td>\n",
       "      <td>290.569300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>166.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>533.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>692.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>888.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>486.000000</td>\n",
       "      <td>2878.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target_len   source_len\n",
       "count  1289.000000  1289.000000\n",
       "mean     85.415050   737.681924\n",
       "std      41.921667   290.569300\n",
       "min       9.000000   166.000000\n",
       "25%      58.000000   533.000000\n",
       "50%      80.000000   692.000000\n",
       "75%     106.000000   888.000000\n",
       "max     486.000000  2878.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev['target_text'] = dev[target_column]\n",
    "dev['source_text'] = \"summarize: \" + dev[source_column]\n",
    "\n",
    "dev['target_len'] = dev[\"target_text\"].str.split().str.len()\n",
    "dev['source_len'] = dev[\"source_text\"].str.split().str.len()\n",
    "dev[['target_len','source_len']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11e74c64-a0d2-486d-86ff-c7482fdf554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[[\"target_text\", \"source_text\"]]\n",
    "dev = dev[[\"target_text\",\"source_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8c4b884-81ac-4145-a3d5-8d7c72c066cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleT5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8948a01-b24d-4bb8-be7a-e1eb26d1add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.from_pretrained(model_type=\"t5\",model_name = \"t5-base\") # large  \"google/mt5-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0f589c3-e6dd-4f55-843e-3d5d81d783eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "#del data, model\n",
    "gc.collect()\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b16ff614-50ad-4a7d-8b0a-b9e4a2c62adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdfe595a-4e1e-4aaa-90fa-f1aa3e8b8ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-dd659cb7-e00c-a571-5359-f0f188a08fee]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842dc4f4dbea4af6bf8dd75a35e08d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175818255e3f426fb12bf01e4db1913d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.2366\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 1.9315\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.7201\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train, #45_56\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 150,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 8, max_epochs = 3, # 9 for base\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "957ad862-9d19-4c47-916f-6d282e1709b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-69415620-de6c-329d-ef8d-9c9c937f4850]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac4493987744e2c9f1c23291133f134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1130763745cb4adb936e9be9355f5ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.2256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 1.9291\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.7165\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train, #45_56\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 150,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 8, max_epochs = 3, # 9 for base\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e472926a-4724-4d3e-8baa-f386d090c904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-1cad794e-e425-8f4b-3a02-a512bba3497a]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73abcbf9dac542f5999fa141ca46f3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/brno3-cerit/home/vajp02/.conda/envs/myenv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 256 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 42\n",
      "/storage/brno3-cerit/home/vajp02/.conda/envs/myenv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 256 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49048f4e568e4e0cafd289df029d88c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.2921\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 1.9845\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.7736\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train, #45_56\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 150,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 8, max_epochs = 3, # 9 for base\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8be3e1e3-4ce9-4cb7-bcb1-979a5d7ab2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-bceb1af3-48fa-7240-a710-a81ba0d3ebc5]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c67e90a629400fb65825714247ae83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d79382f4d84e2faec27c7ab4dbf75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.2872\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 1.9705\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.7516\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train, #45_56\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 150,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 8, max_epochs = 3, # 9 for base\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95436646-fe30-4015-b195-0d1d9cd89278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-129c91a9-fac6-0c27-6de4-14ecc17b6501]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de85b92368814705a2c05054bd43b334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ecb8e5b0f664dd788b651779f678de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.2267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 1.922\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.7125\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train, #45_56\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 150,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 8, max_epochs = 3, # 9 for base\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2625990-7cb9-424c-9541-a06b70f831c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-129c91a9-fac6-0c27-6de4-14ecc17b6501]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3a5db736ed49e7a13574c5889e693e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7734942bc7a46eaa3621aa1afabe9a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.2506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 1.9477\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.736\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train, #45_57\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 150,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 8, max_epochs = 3, # 9 for base\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ac28610-b965-4dab-91c5-aacddbc8b5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-c0eb6ae4-7a40-b947-996f-5811490f6f65]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c80a12037f44219784ead43f457cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa4b2cd4dc648ce89ec7a0ff5557169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 1.9299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.7274\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train, #45_56\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 150,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 8, max_epochs = 3, # 9 for base\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8162dbe9-2fee-4290-91a2-71d16832a9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-129c91a9-fac6-0c27-6de4-14ecc17b6501]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e7676d51374d2ebafccc56e422a73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3030d3b9144c5d85c5c67c975a4b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.2565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 1.9485\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.7415\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train, #45_56\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 150,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 8, max_epochs = 3, # 9 for base\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6584f6c7-b306-4745-8701-95a8f19e550d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-129c91a9-fac6-0c27-6de4-14ecc17b6501]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ed14abe7c54de388f2778b361918f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf87b8906f74970aad704d499948a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.2759\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 1.9622\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.7635\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train, #45_55\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 150,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 8, max_epochs = 3, # 9 for base\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ddc0986-44cd-44e1-936c-6c1ec9812a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-129c91a9-fac6-0c27-6de4-14ecc17b6501]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a265c00284a84c46971a6716715b25e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90f86b86694449bb39381b238b24efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.3017\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 1.992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.7793\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train, #45_54\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 150,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 8, max_epochs = 3, # 9 for base\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0828b33-4562-4dc5-8f1a-bc4fc46d920f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-129c91a9-fac6-0c27-6de4-14ecc17b6501]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe3d55683b0142a2a5b7c95f9ca733b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0d571e422a45a0ae8a95232a25a4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.2577\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 1.9523\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.7442\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train, # 57\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 150,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 8, max_epochs = 3, # 9 for base\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d7f664b-cc01-45a7-8212-a6bfa5f8705f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-129c91a9-fac6-0c27-6de4-14ecc17b6501]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d13c9d09ca24750901566797f98bd08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4a820252404b1e917f50df67e0f551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.3315\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 2.0217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.8072\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train,\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 150,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 8, max_epochs = 3, # 9 for base\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d20d4ac6-7227-4202-8052-9ab9668763c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-129c91a9-fac6-0c27-6de4-14ecc17b6501]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9286dc3163441ea8eab1dc98f48285d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a92742ac8c14c238a158c191b43f9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.3992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 2.0866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.8762\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train,\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 150,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 8, max_epochs = 3, # 9 for base\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc53afd8-c9c9-4595-b185-6a0e5c47d403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-129c91a9-fac6-0c27-6de4-14ecc17b6501]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7660f8062e34459ab23ebebfc74c638b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d3c9b37bbb4daf9677b9199824304f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.3697\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 2.0543\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.8423\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train,\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 150,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 8, max_epochs = 3, # 9 for base\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "581a581b-5d36-42a0-8af1-3e92c89a1f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-c85b1185-eb3f-7f99-412a-2486fe49bf7c]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed713d3987a4e4e82a89090baa1b493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5c6ee01ead4aecbb3dd299a3a226a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.3461\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 2.0335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.8241\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train,\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 150,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 8, max_epochs = 3, # 9 for base\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e14ea61-de57-4c9c-9195-3a2c7bd8be80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-c85b1185-eb3f-7f99-412a-2486fe49bf7c]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e210cac286c84227976a0c515755b46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54805c08723e4a278c19ea8d6b380a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.2937\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 1.9792\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.7665\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train,\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 150,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 8, max_epochs = 3, # 9 for base\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22411518-0b65-4944-842e-2429da888f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-bceb1af3-48fa-7240-a710-a81ba0d3ebc5]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587e107f38fe47fb8537e9c6422795b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d082f8b4f04757b0b7692ef4a5d31e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.059\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.091 >= min_delta = 0.0. New best score: 1.882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 1.7684\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 1 records. Best score: 1.882. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.5647\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train,\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 100,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 9, max_epochs = 3, # 18\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "039311ea-42b2-46dc-a53f-9cdc948a8a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-a527da35-0f6b-a3bf-de28-5bb4f9ba4001]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f161aeff15b44ebb12fc7586c8a222a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75905bb9971a479b90c092be645039bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 0 equal to 2.1297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1 equal to 1.8196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2 equal to 1.6134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 3 equal to 1.444\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 4 equal to 1.2971\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 5 equal to 1.1629\n"
     ]
    }
   ],
   "source": [
    "model.train(train_df = train,\n",
    "            eval_df = dev, \n",
    "            source_max_token_len = 1200,  #2000 max_explanation_tokens\n",
    "            target_max_token_len = 100,  #100 max_shortexplanation_tokens\n",
    "            batch_size = 9, max_epochs = 6, # 18\n",
    "            use_gpu = True,\n",
    "            outputdir = output_dir,\n",
    "            early_stopping_patience_epochs = 0) # 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
