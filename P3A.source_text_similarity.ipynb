{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26739ce4-5ee2-4659-98e2-0495d6105d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import models, losses\n",
    "import pandas as pd\n",
    "from sentence_splitter import SentenceSplitter, split_text_into_sentences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import cdist\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f57a28ad-6f42-43db-bc7c-efdd044fca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee8cbdc3-46cb-41a2-a08b-5115bd519101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model_name = \"./Data/Demagog/Models/d-bert-2021-11-27-12-09-46\"\n",
    "base_model_name = \"all-mpnet-base-v2\"           #\"./Data/Bert/fine-tuned-bert-2022-02-21-16-20-51\"   #\"all-mpnet-base-v2\"          #\"paraphrase-multilingual-mpnet-base-v2\" all-mpnet-base-v2\n",
    "data_import_path = \"./Data/Preprocessed/data_with_filled_explanations_17.2.2022_no_duplicates_preprocessed.pickle\"\n",
    "source_col_name = \"explanation_prep\"  #\"explanation_prep\"  \"statement_explanation_prep\"                     #\"source_text_shorter\"  # \"source_text_shorter\" source_text\n",
    "targer_col_name = \"shortExplanation_prep\"                         #\"target_text\"\n",
    "neighbours = 4\n",
    "data_with_similarity_dir = \"./Data/Similarity/data_{}_{}.pickle\".format(source_col_name,neighbours)\n",
    "data_embeddings_dir = \"./Data/Embeddings/embed_{}_{}.pkl\".format(source_col_name, targer_col_name)\n",
    "min_no_sentence_source_text = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb66fea-e69f-4a01-a336-e1d0d80ca7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A100-SXM4-40GB'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de61f074-bc8b-4711-8881-f3a535ac4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_multi_index(lst):\n",
    "    return list(range(lst))\n",
    "\n",
    "def select_longer_claims(df):\n",
    "    \n",
    "    #to_del = df[(df.type == \"train\") & (df.source_text_sentences_len <= min_no_sentence_source_text)].id.to_list()\n",
    "    #df = df[~ df.id.isin(to_del)]\n",
    "    df = df.explode(['source_text_sentences',\"source_text_sentences_index\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def split_data(dat, sour_col, targ_col):  \n",
    "    \n",
    "    dat[\"label\"] = list(range(len(dat)))\n",
    "    dat['source_text'] = dat[sour_col]\n",
    "    dat['target_text'] = dat[targ_col]\n",
    "\n",
    "    splitter = SentenceSplitter(language='en')\n",
    "    dat['source_text_sentences'] = dat['source_text'].apply(lambda x : splitter.split(text = x))\n",
    "    dat['source_text_sentences_len'] = dat['source_text_sentences'].str.len()\n",
    "    dat['source_text_sentences_index'] = dat['source_text_sentences_len'].apply(lambda x : add_multi_index(x))\n",
    "\n",
    "    #dat = dat[[\"id\",\"source_text\", \"target_text\", \"source_text_sentences\", \"source_text_sentences_len\",\"source_text_sentences_index\",\"type\"]]\n",
    "    return dat\n",
    "\n",
    "\n",
    "def embeddings_sentence_bert(text, IsBase, Bert_name):  \n",
    "    \n",
    "        start = time.time()\n",
    "        if IsBase==True:            \n",
    "            model = SentenceTransformer(Bert_name, device = 'cuda:0')  # model  bert-base-uncased           \n",
    "        else:     \n",
    "                     \n",
    "            word_embedding_model = models.Transformer(Bert_name)\n",
    "            # Apply mean pooling to get one fixed sized sentence vector\n",
    "            pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                                           pooling_mode_mean_tokens=True,\n",
    "                                           pooling_mode_cls_token=False,\n",
    "                                           pooling_mode_max_tokens=False)\n",
    "            model = SentenceTransformer(modules=[word_embedding_model, pooling_model], device = 'cuda:0')\n",
    "\n",
    "        \n",
    "        #Sentences are encoded by calling model.encode()\n",
    "        sentence_vectors = model.encode(text,show_progress_bar=True, batch_size = 500)            \n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        print(\"Time for creating \"+ str(len(sentence_vectors))+\" embedding vectors \" + str((end - start)/60))\n",
    "        print('Model used :'+ Bert_name )\n",
    "\n",
    "        return sentence_vectors\n",
    "    \n",
    "def get_similarity_matrix(df,metric = \"cosine\"):\n",
    "     \n",
    "    df = df.to_list()    \n",
    "    A =  np.array(df,dtype=float)\n",
    "    A_sparse = sparse.csr_matrix(A)\n",
    "\n",
    "    if (metric==\"cosine\"):\n",
    "        similarities = cosine_similarity(A_sparse)\n",
    "        similarities_norm = (1/(1+similarities))                #      (1/(1+similarities))\n",
    "    elif(metric==\"euclidean\"):\n",
    "        similarities = euclidean_distances(A_sparse)\n",
    "        similarities_norm= (1/(1+similarities))\n",
    "    return np.mean(similarities_norm, axis=0)\n",
    "\n",
    "def get_lof_score(dat):\n",
    "    ad = []\n",
    "    try:\n",
    "        lof = LocalOutlierFactor(n_neighbors = neighbours,metric='cosine')\n",
    "        embeds = dat.to_list()\n",
    "        lof.fit_predict(embeds).tolist()\n",
    "        return 1 - (1/(1-(lof.negative_outlier_factor_)))\n",
    "    except:\n",
    "        return [0.51]*len(dat)\n",
    "\n",
    "def create_embeddings(df):\n",
    "    sentences_lst = df[\"source_text_sentences\"].tolist() #answer\n",
    "    embeddings = embeddings_sentence_bert(sentences_lst, True, base_model_name)\n",
    "    df[\"source_text_sentences_embed_base\"] =  embeddings.tolist()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0885c44-f2e4-4552-9de2-ca90de5134f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12891"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(data_import_path)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "350816a0-d21a-47af-8d57-1798c41e533a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>statementTokensLength</th>\n",
       "      <th>explanationTokensLength</th>\n",
       "      <th>shortExplanationTokensLength</th>\n",
       "      <th>statementexplanationTokensLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12891.000000</td>\n",
       "      <td>12891.000000</td>\n",
       "      <td>12891.000000</td>\n",
       "      <td>12891.000000</td>\n",
       "      <td>12891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6491.162672</td>\n",
       "      <td>18.412691</td>\n",
       "      <td>775.487937</td>\n",
       "      <td>85.352416</td>\n",
       "      <td>793.333721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3752.628466</td>\n",
       "      <td>8.066301</td>\n",
       "      <td>288.562379</td>\n",
       "      <td>42.275294</td>\n",
       "      <td>288.266961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3241.500000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>588.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6481.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>736.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>755.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9744.500000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>934.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>952.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12994.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>2912.000000</td>\n",
       "      <td>1121.000000</td>\n",
       "      <td>2899.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  statementTokensLength  explanationTokensLength  \\\n",
       "count  12891.000000           12891.000000             12891.000000   \n",
       "mean    6491.162672              18.412691               775.487937   \n",
       "std     3752.628466               8.066301               288.562379   \n",
       "min        1.000000               3.000000                23.000000   \n",
       "25%     3241.500000              13.000000               570.000000   \n",
       "50%     6481.000000              17.000000               736.000000   \n",
       "75%     9744.500000              23.000000               934.000000   \n",
       "max    12994.000000              73.000000              2912.000000   \n",
       "\n",
       "       shortExplanationTokensLength  statementexplanationTokensLength  \n",
       "count                  12891.000000                      12891.000000  \n",
       "mean                      85.352416                        793.333721  \n",
       "std                       42.275294                        288.266961  \n",
       "min                        2.000000                         45.000000  \n",
       "25%                       58.000000                        588.000000  \n",
       "50%                       80.000000                        755.000000  \n",
       "75%                      106.000000                        952.000000  \n",
       "max                     1121.000000                       2899.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d111b86c-7b4c-4a0c-afed-640ab8dee644",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = split_data(data, source_col_name, targer_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e3a3323-c0b6-446d-a32b-b68774728b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465236"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shorter = select_longer_claims(data)\n",
    "len(data_shorter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0166ba73-9ed0-4abb-a20e-0d46147bb2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shorter.to_pickle(\"Data/backup/data150.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a2f16ea-4849-4cd5-a8aa-1828a7a52234",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shorter = pd.read_pickle(\"Data/backup/data150.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "075491ed-e805-485f-8b6f-9e08b1c99559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'reviewer', 'date', 'statement', 'explanation',\n",
       "       'shortExplanation', 'truth_o_meter', 'tags', 'url', 'statement_prep',\n",
       "       'explanation_prep', 'shortExplanation_prep',\n",
       "       'statement_explanation_prep', 'statementTokensLength',\n",
       "       'explanationTokensLength', 'shortExplanationTokensLength',\n",
       "       'statementexplanationTokensLength', 'label', 'source_text',\n",
       "       'target_text', 'source_text_sentences', 'source_text_sentences_len',\n",
       "       'source_text_sentences_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shorter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2028c0c-ae3e-4c5f-95d3-6f33ce40c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SentenceTransformer(base_model_name, device = 'cuda:0')\n",
    "sentences_lst = data_shorter[\"source_text_sentences\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bd9178a-cc32-44e4-9178-f329d33da557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465236"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_shorter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cb34660-7258-4188-9df1-9f0d22893afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412d916062bb4b3294bce23b4bce0075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/931 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for creating 465236 embedding vectors 2.89707262913386\n",
      "Model used :all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "embeddings = embeddings_sentence_bert(sentences_lst, True, base_model_name)               #  model.encode(sentences_lst, show_progress_bar=True, batch_size = 500)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f9ab8d2-a761-444a-80e1-94f7c1ce591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(data_embeddings_dir, 'wb') as f:\n",
    "#    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7affbf7-416c-44d1-b380-619fe9fb6771",
   "metadata": {},
   "source": [
    "# Read data and convert huge numpy array to list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fee74f4-e6c5-4855-b6b6-9b584b3fdbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_shorter = pd.read_pickle(\"data77.pickle\")\n",
    "#with open(data_embeddings_dir, 'rb') as f:\n",
    "#    embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "747e2156-f247-45ad-9ebf-80ec3a0b3d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bc2437b06144e48b88d464d4aaba78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/465236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.DataFrame([[i] for i in tqdm(embeddings)]).rename(columns={0:'source_text_sentences_embed_base'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a89d9bd-9d87-4649-a0e9-43c72587b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shorter = pd.concat([data_shorter.reset_index(), data.reset_index()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42a4905b-05ea-4bc3-9668-84852beae3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_shorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "493a810b-7eaf-429e-a31a-b96c0f2eb3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(n_neighbors = neighbours, metric = 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1845260-41c2-48aa-b9d2-b65c1208716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ef7908d-1460-45e9-97f4-d9b7c4759313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12891/12891 [00:13<00:00, 964.26it/s]\n"
     ]
    }
   ],
   "source": [
    "data_shorter[\"LOF_base\"] = data_shorter.groupby('id',sort = False)['source_text_sentences_embed_base'].progress_apply(get_lof_score).explode().to_list()\n",
    "data_shorter.to_pickle(data_with_similarity_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1e98de5-3a33-47ce-9e78-7c6267e830ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'id', 'reviewer', 'date', 'statement', 'explanation',\n",
       "       'shortExplanation', 'truth_o_meter', 'tags', 'url', 'statement_prep',\n",
       "       'explanation_prep', 'shortExplanation_prep',\n",
       "       'statement_explanation_prep', 'statementTokensLength',\n",
       "       'explanationTokensLength', 'shortExplanationTokensLength',\n",
       "       'statementexplanationTokensLength', 'label', 'source_text',\n",
       "       'target_text', 'source_text_sentences', 'source_text_sentences_len',\n",
       "       'source_text_sentences_index', 'index',\n",
       "       'source_text_sentences_embed_base', 'LOF_base'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shorter.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22177bb3-eb59-474c-a60f-8949e3da516c",
   "metadata": {},
   "source": [
    "# Concatenate without embeddings (if too big numpy array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db9e47bf-9e3f-4f3b-9145-66f3c42bb6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.read_pickle(\"./Data/Similarity/data_whole_title_embed_text_title_30K.pickle\")\n",
    "data_shorter  = pd.read_pickle(\"./Data/Similarity/data_whole_title_embed_text_title_150K.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e066ee3-fcd0-44d9-aada-1256359f9156",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.type != \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbdc3023-a692-4643-964c-04f81047d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('source_text_sentences_embed_base', inplace=True, axis=1)\n",
    "data_shorter.drop('source_text_sentences_embed_base', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "216ca27e-adbd-421c-adfa-a5563f22c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_res = pd.concat([data, data_shorter], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f10c593-4383-480b-bf54-7b5c003d5767",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_res.to_pickle(data_with_similarity_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc167ed-b094-4543-960e-6486a587bd6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
